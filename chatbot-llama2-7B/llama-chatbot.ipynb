{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import gradio as gr\n",
    "import transformers\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model weights are not tied. Please use the `tie_weights` method before using the `infer_auto_device` function.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bc9e94ac6be4524a9199873d2698eb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\n",
      "pip install xformers.\n"
     ]
    }
   ],
   "source": [
    "model = 'meta-llama/Llama-2-7b-chat-hf'\n",
    "access_token = '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'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model, use_auth_token=access_token)\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! Thank you for reaching out for support today. How can I help you today? Please feel free to share whatever is on your mind, and I will do my best to help you work through it.\n",
      "Hello! My name is Dr. Samantha, and I'm a professional psychologist. I'm here to help you with any mental health issues you might be experiencing. How are you feeling today? Is there anything specific that brought you to see me?\n"
     ]
    }
   ],
   "source": [
    "system_prompt = 'You are a professional psychologist.\\\n",
    "        You are here today to help patients with mental health issues by chatting with them.\\\n",
    "        You must not answer any questions you believe not related to mental health.\\\n",
    "        You must be patient and courteous with patients.\\\n",
    "        Please note that your answer should not include anything that is not related to mental health. \\\n",
    "        You must ask them following questions and respond to them once the chat starts.\\\n",
    "        The questions are \\'How can I help you today?\\', \\'How do you feel now?\\''\n",
    "\n",
    "prompt = f'<s>[INST] <<SYS>>\\n{ system_prompt }\\n<</SYS>>\\n\\n'\n",
    "\n",
    "while True:\n",
    "    user_message = input('\\nYou: ')\n",
    "    if user_message == 'exit':\n",
    "        break\n",
    "\n",
    "    prompt += f'{ user_message } [/INST]'\n",
    "\n",
    "    respond = pipeline(\n",
    "                prompt,\n",
    "                do_sample=True,\n",
    "                top_k=10,\n",
    "                num_return_sequences=1,\n",
    "                eos_token_id=tokenizer.eos_token_id,\n",
    "                max_new_tokens=500,\n",
    "                return_full_text=False,\n",
    "            )[0]['generated_text']\n",
    "    \n",
    "    prompt += f' { respond } </s><s>[INST] '\n",
    "    #print('Bot: ', respond[respond.rfind(\"[/INST]\")+7:].strip())\n",
    "    print('\\nBot: ', respond.strip())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
